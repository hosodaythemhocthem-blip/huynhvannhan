import { GoogleGenerativeAI, GenerativeModel } from "@google/generative-ai";

// 1. Láº¥y API Key dÃ nh riÃªng cho Vite
const API_KEY = import.meta.env.VITE_GEMINI_API_KEY || "";

const genAI = new GoogleGenerativeAI(API_KEY);

// 2. HÃ m khá»Ÿi táº¡o model chuáº©n
const getModel = (isJson: boolean = false, temperature: number = 0.7): GenerativeModel => {
  if (!API_KEY) {
    console.error("âŒ API Key bá»‹ trá»‘ng! HÃ£y kiá»ƒm tra láº¡i biáº¿n VITE_GEMINI_API_KEY trÃªn Vercel.");
  }

  // Sá»¬A Lá»–I 404: DÃ¹ng tÃªn model chuáº©n xÃ¡c nháº¥t cho báº£n á»•n Ä‘á»‹nh
  return genAI.getGenerativeModel({
    model: "gemini-1.5-flash", 
    generationConfig: {
      temperature,
      ...(isJson ? { responseMimeType: "application/json" } : {}),
    },
  });
};

/* =========================================================
   ğŸš€ CÃC SERVICE CHÃNH (GIá»® NGUYÃŠN LOGIC Cá»¦A Báº N)
========================================================= */
export const geminiService = {
  // Parse Ä‘á» thi
  async parseExamWithAI(text: string) {
    if (!text.trim()) return null;
    const model = getModel(true, 0.1);
    const prompt = `Báº¡n lÃ  chuyÃªn gia giÃ¡o dá»¥c. Chuyá»ƒn vÄƒn báº£n sau thÃ nh JSON: ${text}`;
    
    try {
      const result = await model.generateContent(prompt);
      const response = await result.response;
      return JSON.parse(response.text().replace(/```json|```/gi, "").trim());
    } catch (error) {
      console.error("Lá»—i AI:", error);
      throw error;
    }
  },

  // Chat tá»± do
  async chatWithAI(prompt: string): Promise<string> {
    const model = getModel(false, 0.7);
    try {
      const result = await model.generateContent(prompt);
      return result.response.text();
    } catch (error) {
      return "AI Ä‘ang báº­n, báº¡n thá»­ láº¡i sau nhÃ©!";
    }
  }
  // ... Báº¡n cÃ³ thá»ƒ copy láº¡i cÃ¡c hÃ m generateExam, gradeEssay tá»« báº£n trÆ°á»›c cá»§a mÃ¬nh vÃ o Ä‘Ã¢y
};
